\section{Related work}
\label{sec:related_work}

A crucial component of Web Science research is the ability
 to collect data about the Web.
To do so there is growing awareness for the need for either
 a Web Observatory or Web Observatories \cite{10.1109/MIS.2013.50}.
These provide facilities for both gathering and providing analytics about
 information for the Web.
A distinguishing feature of a Web Observatory is that it focuses
``...specifically on data about the Web (rather than all data on the Web)...'' \cite{10.1109/MIS.2013.50}.
A number of initial Web Observatories have begun to be built.
For example, \cite{Gloria:2013:EWS:2487788.2488170} outlines
 the development of observatories built by Rensselaer Polytechnic Institute
 that focus on studying the Web from different domain perspectives:
 science, open government, health and social science.
Other observatories are being constructed to tackle these domains as well
 (e.g. science~\cite{Naveed:2011:AAT:2527031.2527033}
 or health~\cite{luciano2013emergent}).
Several observatories focus on social interactions.
For example, The Truthy Web Observatory\footnote{\url{http://truthy.indiana.edu}}
 enables the study of social media, in particular,
 information diffusion on the Web \cite{McKelvey2013wow}.
Likewise, the L3S observatory looks at live analysis of
 the social web~\cite{Diaz-Aviles:2013:LAM:2487788.2488169}.
At a more general level,
 the LAWA project\footnote{\url{http://www.lawa-project.eu}}
 focuses on the tracking of entities on the Web
 over time~\cite{Spaniol:2012:TEW:2187980.2188030}
 and the Koblenz Network Collection~\cite{Kunegis:2013:KKN:2487788.2488173}
 gathers a variety of Web networks for study.

All these observatories primarily focus on the gathering and analysis
 of data about the interactions of humans with each other
 as mediated by the Web and the subsequent impact on the Web itself.
In some sense this is to be expected,
 as the relationship between social and technical constructs
 is a hallmark of Web Science research~\cite{Hendler:2008:WSI:1364782.1364798}.
Our work, however, takes a different track.
We focus on constructing a Web Observatory from the perspective of
 determining the Web hospitableness for machines.
We see our work as complimentary to this existing work.
It can rely on similar infrastructure but instead looks at
 analyses for determining the movement of the Web towards machine usability.

Bearing some similarity to our work is the the large amount of
 literature\footnote{See Akamai's State of
   the Internet \url{http://www.akamai.com/stateoftheinternet/}
   or the ACM Internet Measurement Conference~\cite{Byers:2012:2398776}}
 on the network status of the Internet.
Our work differs in that we are not looking at the readability
 or location of hosts or data on the network, but instead on
 the usability of the data by machines
 (e.g. downloading, parsing, and reasoning).

The closest work to that presented here is on surveying the status of
 Linked Data available in various forms.
Some surveys have focused on its availability through
 crawling the Web~\cite{rdfa-deployment2013, linkedatadynamics2013}.
Our work differs in that instead of just availability,
 we catalog the gap between the current status of the data
 and what is needed for machine friendliness.
Other work has looked at the availability of
 Linked Data SPARQL endpoints\footnote{\url{http://sparqles.okfn.org}}\cite{sparqlready2013}.
These approaches have cataloged numerous issues with the availability
 and uptime of Linked Data that is disseminated in this fashion.
Our work differs in that we look at downloadable data
 and not just that which is exposed via SPARQL.
This work shares many similarities with
 the work of~\cite{conf/www/HoganHPDP10} that initiated
 the Pedantic Web project\footnote{\url{http://pedantic-web.org}},
 which aims to improve the quality of RDF data on the Web.
That initial work found many of the same errors we have discovered.
Our work differs in that we provide a systematic survey
 of currently available data with a particular focus on
 identifying where data lands, on a gradient from complete unavailability
 to full machine friendliness.
By studying machine processability in terms of a gradient,
 we are able to zoom in on what are today's mayor culprits
 towards a machine-processable Web.

