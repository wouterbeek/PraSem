\section{Evaluation}
\label{sec:evaluation}

\begin{table*}[ht!]
  \centering
  \caption{Overview of the number of partitions per approach.}
  \label{tab:partitions}
  \begin{tabular}{|l|l|l|l|l|l|}
    \hline
    \textbf{Dataset}       & \textbf{Number of} & \textbf{Number of}    & \textbf{Number of}    & \textbf{$I(f_1 : f_\M)$} & \textbf{Number of} \\
                           & \textbf{typesets}  & \textbf{propertysets} & \textbf{fingerprints} & (expressed in percents)  & \textbf{triples}   \\
    \hline
    \hline
    socialsemweb-thesaurus & 154 & 225 & 303 & 95.4\% & 32,112 \\
    \hline
    camera-deputati-linked-data & 2 & 11 & 40 & 100\% & 87,221 \\
    \hline
    ysa & 7 & 193 & 283 & 100\% & 252,325 \\
    \hline
    southampton-ac-uk-phonebook & 5 & 15 & 16 & 100\% & 26,553 \\
    \hline
    eagle-i-alaska & 2 & 9 & 9 & 100\% & 270,014 \\
    \hline
    rkb-explorer-os & 11 & 16 & 16 & 40.5\% & 148,931 \\
    \hline
    traditional-korean-medicine & 43 & 260 & 286 & 68.6\% & 51,932 \\
    \hline
    tekord & 2 & 14 & 15 & 100\% & 52,274 \\
    \hline
    eprtr & 2 & 3 & 95 & 100\% & 1,276,862 \\
    \hline
    passim & 11 & 81 & 187 & 65.5\% & 17,431 \\
    \hline
    vivo-scripps-research-institute & 121 & 583 & 685 & 96.4\% & 405,993 \\
    \hline
    us-state-by-state-behavioral-health-resources & 2 & 25 & 36 & 100\% & 10,538 \\
    \hline
    greek-legal-entities & 4 & 5 & 72 & 100\% & 527,554 \\
    \hline
    lista-encabezamientos-materia & 2 & 3 & 3 & 100\% & 19,156 \\
    \hline
    europeana-lod & 6 & 12 & 12 & 100\% & 41,591 \\
    \hline
    eurostat-rdf & 2 & 5 & 5 & 100\% & 13,997 \\
    \hline
    southampton-ac-uk-bus-routes & 4 & 6 & 55 & 100\% & 20,484 \\
    \hline
    iso-3166-2-data & 5 & 5 & 5 & 17.1\% & 12,001 \\
    \hline
    eprtr & 19 & 32 & 125 & 94.2\% & 30,313 \\
    \hline
    capgrids & 2 & 4 & 4 & 100\% & 22,596 \\
    \hline
    camera-deputati-linked-data & 2 & 2 & 2 & 100\% & 25,943 \\
    \hline
    europeana-lod & 6 & 22 & 22 & 100\% & 519,877 \\
    \hline
    rkb-explorer-epsrc & 14 & 24 & 443 & 99.6\% & 229,157 \\
    \hline
    camera-deputati-linked-data & 2 & 5 & 68 & 100\% & 19,238 \\
    \hline
  \end{tabular}
\end{table*}

\begin{table*}[ht!]
  \label{tab:mutual_information}
  \centering
  \caption{
    Overview of the entropy of the typeset ($f_1$) conditional on
    either the propertyset ($f_2$) or the generic fingerprint ($f_\M$).
  }
  \begin{tabular}{|l|l|l|l|l|l|}
    \hline
    \textbf{Dataset} & \textbf{$H(f_1)$} & \textbf{$H(f_1 \mid f_2)$} & \textbf{$H(f_1 \mid f_\M)$} & \textbf{Improvement} & \textbf{Number of triples}\\
    \hline
    \hline
    socialsemweb-thesaurus & 1.547 & 0.077 & 0.071 & 0.39\% & 32,112 \\
    \hline
    traditional-korean-medicine & 3.239 & 1.019 & 1.017 & 0.062\% & 51,932 \\
    \hline
    passim & 1.214 & 0.421 & 0.419 & 0.16\% & 17,431 \\
    \hline
    vivo-scripps-research-institute & 2.389 & 0.092 & 0.087 & 0.21\% & 405,993 \\
    \hline
    rkb-explorer-epsrc & 2.57 & 0.033 & 0.01 & 0.89\% & 229,157 \\
    \hline
  \end{tabular}
\end{table*}

We compare three different fingerprints for partitioning the resources
 into distinct ``kinds'': we can do so based on the set of classes
 associated with a resource $f_1$ (definition \ref{def:class}),
 its set of predicate terms $f_2$ (definition \ref{def:predicate}),
 and its generic fingerprints $f_\M$ (definition \ref{def:fingerprint}),
 as explained in Section~\ref{sec:fingerprints}.
To evaluate how much information a kind provides about a resource,
 and to compare the granularity of the methods,
 we use the information theoretic measures of entropy,
 conditional entropy, and mutual information.

\subsection{Measures of Information}

Let $P$ be a probability distribution, and let $X$ and $Y$ be random
variables that take values in $\X$ and $\Y$ respectively. The
\emph{entropy} of $X$ is defined by
\[H(X)=\sum_{x\in\X}-P(X=x)\log P(X=x).\]
It can be interpreted as the expected number of bits needed to encode
the value of $X$ upon a draw from $P$.

If $X$ and $Y$ are dependent, then knowing the value of $Y$ helps to
predict, and therefore encode, $X$. This is expressed by the
\emph{conditional entropy} of $X$ given $Y$:
\[H(X|Y)=\sum_{x\in\X,y\in\Y}-P(X=x,Y=y)\log
P(X=x|Y=y).\]
This is the expected number of bits needed to encode $X$, given
the value of $Y$. Conditioning is always helpful: we must have $0\le
H(X|Y)\le H(X)$. Clearly, $H(X|X)=0$.

The difference between $H(X)$ and $H(X|Y)$ is the amount of
information that $Y$ provides about $X$; as it turns out this property
is symmetric. This is the \emph{mutual information} between $X$ and $Y$:
\[I(X:Y)=H(X)-H(X|Y)=H(Y)-H(Y|X).\]
Mutual information has the property that
$I(X:X)=H(X)-H(X|X)=H(X)$. For more information about basic
information theory please refer to Shannon's classical paper
\cite{Shannon1948} or the textbook \cite{cover1991}.

In this study, given a data set $D$ we define $P$ to be the
\emph{empirical distribution} on URIs and blank nodes; i.e. a draw
from $P$ produces a term corresponding to one of the resources in the
data, selected uniformly at random. We are interested in the random
variables $\sigma$, $\pi$ and $\phi$ defined in
Section~\ref{sec:approach}, which represent, respectively, the type set
of the resource, the predicate set, and the fingerprint. For the
fingerprint, we abbreviate $\phi(t)=\phi_{\M_\tn{mdl}}(t)$: we always
use the model selected by the MDL procedure as described in
Section~\ref{sec:implementation}.

\subsection{Evaluation results}

The evaluation was run on datasets that were scraped from Datahub.
Datahub is a portal for registering open datasets,
 mostly coming from the academic domain.
The scraper uses the CKAN API.\footnote{\url{http://docs.ckan.org}}
CKAN is an open-source data portal platform
 that allows datasets that are published on the Web to be catalogued.
The results we show here are derived for the first 24 datasets
 that were scraped by the script and that contained
 more than 10,000 triples\footnote{
  Datasets on Datahub containing less than 10,000 triples
  are often either partial datadumps or meta-descriptions of datasets
  stored elsewhere.
 }.

Table {tab:partitions} shows the number of partitions for each of the three
 compared approaches.
Since the number of propertysets is a lower bound to the number of fingerprints,
 the number of fingerprints always exceeds the number of propertysets.

Another result is that the generic fingerprint $f_\M$ is
 only a slightly better predictor
 of the typeset than the propertyset is,
 reproducing and only slightly improving on
 the researched performed in \cite{GottronKSS13}.
Table \ref{tab:mutual_information} shows those cases for which
  the conditional entropy of the typeset given the generic fingerprint
 is larger than
  the conditional entropy of the propertyset given the generic fingerprint.
(The former can never be smaller than the latter.)
